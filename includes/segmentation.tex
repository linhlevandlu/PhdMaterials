\chapter{Segmentation}
\section{Canny algorithm}
In 1986, \textbf{John F.Canny} had proposed a method to determine the edge in image. This is a technique to detect the useful structure of the object in digital image. Until now, the Canny algorithm\cite{canny1986computational} is used widely for the segmentation in computer vision. The process of Canny algorithm can be described in 4 steps as follows:
\begin{enumerate}
	\item Smoothing the image to reduce the noises by using Gaussian filter
	\item Finding the intensity and direction gradient of each pixel in image
	\item Eliminating the weak edge by using the edge thinning technique.
	\item Applying double threshold to determine the potential edges
\end{enumerate}
	\subsection{Gaussian filter}
	To smooth the image, a Gaussian filter is applied to convolve with the image. This step will help to reduce the effects of the noises on the edge detector. Normally, the equation of a Gaussian kernel with size $(2k+1)$ x $(2k + 1)$  is computed as:
	\begin{equation}
	H_{ij}=\frac{1}{2\pi\sigma^2}exp(-\frac{(i-(k+1))^2 + (j-(k+1))^2}{2\sigma^2});1\leq i,j \leq (2k+1)
	\end{equation}
	where $k$ is the size of kernel, and it should be a odd number.\\
	For example, a 3x3 Gaussian filter with $\sigma = 1 $ as followed:
	\begin{equation}
		G = 
		\begin{bmatrix}
		1 & 2 & 1\\
		2 & 4 & 2\\
		1 & 2 & 1		
		\end{bmatrix}
	\end{equation}	
	
	The selection of the size of the Gaussian kernel is important, it will affect the performance of the detector. If the size of the kernel is large, the detector can be sensitive to noise; otherwise, if the kernel's size is small, the detector can be destroy many strong edge. In the practice, this step is combined into Sobel convolution with a 3x3 kernel, which used to finding the intensity and direction gradients at each pixels of image.
	\subsection{Sobel convolution}
	The points belong to the edge in an image can stay in any direction, so the Canny algorithm uses four filters to detect the edges (vertical, horizontal and two diagonal edges) in the image. And the Sobel operator is used to detect the edges. This operator returns a value for the first derivative in horizontal direction $(G_x)$ and the vertical direction $(G_y)$. From these values, the gradient and direction of edge at each pixel are determined:
	\begin{equation}
		G = \sqrt{{G_x}^2 + {G_y}^2}
	\end{equation}
	\begin{equation}
		\phi = atan2(G_y,G_x)
	\end{equation}
	In this case, the kernel of Sobel convolution is 3x3, and it is also combined the Gaussian filter to smooth the image. The kernels are used to convolute the horizontal direction and vertical direction as follows:
	\begin{equation}
		G_x = 
		\begin{bmatrix}
		-1 & 0 & 1\\
		-2 & 0 & 2\\
		-1 & 0 & 1		
		\end{bmatrix}, 
		G_y = 
		\begin{bmatrix}
		-1 & -2 & -1\\
		0 & 0 & 0\\
		1 & 2 & 1		
		\end{bmatrix}
	\end{equation}
	
	The edge direction angle is rounded to one of four angles which were presented for four directions: vertical, horizontal, and two diagonals $0^o, 45^o, 90^o \text{ and } 135^o$.
	\subsection{Non-maximum suppression}
	Non-maximum suppression is applied to thin the edge in an image. Thus, this operation is used to suppress all the gradient values to 0 except the local maximal. At every pixel, it suppress the gradient value of the center pixels if its magnitude is smaller than the magnitude of one out of two neighbors in the gradient direction. In details:
	\begin{itemize}
	\item If the gradient direction angle is \textbf{0} degree, the point will be considered to be on the edge if the gradient magnitude is greater than the magnitude at pixels in the \textbf{east} and \textbf{west} directions.
	\item If the gradient direction angle is \textbf{45} degree, the point will be considered to be on the edge if the gradient magnitude is greater than the magnitude at pixels in the \textbf{north east} and \textbf{south west} directions.
	\item If the gradient direction angle is \textbf{90} degree, the point will be considered to be on the edge if the gradient magnitude is greater than the magnitude at pixels in the \textbf{north} and \textbf{south} directions.
	\item If the gradient direction angle is \textbf{135(-45)} degree, the point will be considered to be on the edge if the gradient magnitude is greater than the magnitude at pixels in the \textbf{north east} and \textbf{south west} directions.
	\end{itemize}
	\subsection{Double threshold}
	After applying the non-maximum suppression, the edges pixels are presented. However, there are still some edge pixels effected by noise. Double threshold will filter out the edge pixels with the weak gradient value and preserve the edge with the hight gradient value.
	\begin{itemize}
		\item A pixel called strong pixel (hence, it belong to the edge), if the edge pixel's gradient value is higher than the high threshold value.
		\item A pixel will be suppressed, if the edge pixel's gradient value is smaller than the low threshold value.
		\item A pixel called weak pixel (can be belong to the edge or not), if the edge pixel's gradient value is larger than low threshold value and smaller than high threshold value. A weak pixel can be belong to the edge if it connected with a strong pixel in 8-connected; else, it will be suppressed.
	\end{itemize}
	Thus, the accuracy of algorithm is depended on two parameters: the kernel of Gaussian filter and thresholds value. As said before, if we choose incorrect the kernel size of Gaussian filter, we can not reduce the noise or we can remove the real edge. Besides, the values of double threshold is also important to filter out the edge pixels. In practice, 1:3 is the good ratio between lower threshold  and upper threshold in Canny.
	\subsection{Summary}
	With applying double thresholding in the last stage, Canny had provied a strict condition to consider the weak edge as well as remove the pixels which were not belong to the edge. So far, Canny algorithm is good method to determined the edge in image, it is used by many application in image processing.
\section{Suzuki algorithm}
The Canny algorithm had detected the edge in the image. We can apply many difference methods to track the edge. \textbf{S. Suzuki} and \textbf{K. Abe}\cite{suzuki1985topological} had proprosed a method to get the border of object in image. This method is based on the topological structure analysis on binary image.\\[0.2cm]
Following this method, it detects two kinds of border in image. The first is outer border, which is defined by a set of border points between an arbitrary 1-component and the 0-component which surrounds it directly; another type is hole border which refers to the set of border points between a hole and the 1-componet which surrounds the hole directly. In this case, the 1-component (or 0-component) is connected component of 1-pixels (or 0-pixels).\\[0.2cm]
In our case, our purpose is getting the edges which were detectecd by Canny\cite{canny1986computational}. An edge is consider as an outer border or a hole border does not important. So, the Suzuki algorithm could make some changes to fit with our aim. The processes of algorithm is desribed as follows:\\[0.2cm]
Let an input binary image is \textbf{$F=\{f_{ij}\}$}. Set initially $NBD = 1$ (denoted the sequence number of border.)
\begin{enumerate}
	\item Select one of the following:
		\begin{enumerate}
			\item If \textbf{$f_{ij} = 1$} and \textbf{$f_{i,j-1} = 0$}, increment NBD, $(i_2,j_2) \gets (i,j-1)$ (pixel $(i,j)$ is the starting point of an outer border).
			\item If \textbf{$f_{ij} \geq 1$} and \textbf{$f_{i,j+1} = 0$}, increment NBD, $(i_2,j_2) \gets (i,j+1)$ (pixel $(i,j)$ is the starting point of an hole border).
			\item Otherwise, go to step (3)
		\end{enumerate}
	\item From the starting point \textbf{(i,j)}, the process to trace the edge is done by substeps following:
		\begin{itemize}
			\item[2.1] Starting from point $(i_2,j_2)$, look around clockwise the pixels in the neighborhood (8-connected) of $(i,j)$ and find the first non-zero pixel $(i_1,j_1)$. If no non-zero pixel is found, assign -NBD to $f_{ij}$ and go to step (3)
			\item[2.2] $(i_2,j_2) \gets (i_1,j_1)$ and $(i_3,j_3) \gets (i,j)$
			\item[2.3] Starting from the \textbf{next element of the pixel $(i_2,j_2)$} in the counterclock-wise order, check the pixels neighborhood of current pixel $(i_3,j_3)$ to find the first non-zero pixel $(i_4,j_4)$.
			\item[2.4] Chang the value $f_{i_3,j_3}$ of the pixel $(i_3,j_3)$ as follows:
				\begin{enumerate}
					\item If the pixels $(i_3,j_3+1)$ is a 0-pixel examined in the substep (2.3) then $f_{i_3,j_3} \gets -NBD$. Else, $f_{i_3,j_3} \gets NBD$ unless $(i_3,j_3)$ is on an already border.
					\item If the pixels $(i_3,j_3+1)$ is not a 0-pixel examined in the substep (2.3) and $f_{i_3,j_3} = 1$ then $f_{i_3,j_3} \gets NBD$
					\item Otherwise, do not change $f_{i_3,j_3}$.
				\end{enumerate}
			\item[2.5] If $(i_4,j_4) = (i,j)$ and $(i_3,j_3) = (i_1,j_1)$ (coming back to the starting point), then go to step (3); otherwise, $(i_2,j_2) \gets (i_3,j3), (i_3,j_3) \gets (i_4,j_4)$ and go back to step (2.3)
		\end{itemize}
	\item Resume the scan from the pixel $(i,j+1)$. The algorithm is stop when the scan reaches the lower right corner of the image.
\end{enumerate}
