\chapter{Deep Network}
\section{Deep learning}
Deep learning is a part of machine learning. It includes the methods based on learning data representation by allowing the computation on the models that are composed of multiple layers. Each layer extracts the representaion of the input data from the previous layer and computes a new presentation as the input for the next layer. In the hierachy of a model, the higher layers of representation enlarge aspects of the input that is important for discrimination and suppress irrelevant variations. Each level of representations is corresponding to the different level of abstraction. Deep learning methods work on a large dataset using the backpropagation algorithm to improve the result after each step. As other machine learning algorithms, the algorithms for deep learning are also learned in supervised or unsupervised manners.

In recent years, deep learning has been applied in many fields of computer science. First of all is computer vision problems, i.e. image classification, image recognition or keypoints detection problems. In classification, deep learning is used to classify the input into several categories. A common evaluation set of images is the MNIST database \cite{}. MNIST consists $60 000$ training examples and $10 000$ test examples of handwritten digits. Deep learning has become ``super tool" because it has produced more accurate results than the human. Besides MNIST, other databases should also be mentioned in classsification such as ImageNet \cite{}, CIFAR-10, CIFAR-100 \cite{}. If deep learning did not appear, the human will spend a lot of time to classify the images in the giant databases. The second problem is natural language processing \cite{}. Deep learning is used to improve the result of machine translation or language modeling. Google Translate \cite{} is an example-based of machine translation which uses a large end-to-end long short-term memory network to build the system. By learning from millions of examples, Google Translate may translate whole sentences at a time rather than a word. In addition, word embedding \cite{} and sentence embedding \cite{} are known as other techniques of this field where deep learing used to predict the next word (next sentence) in a sentence (a paragraph). Besides, deep learning has been applies in different fields such as speech recognition \cite{}, drug discovery and toxicology \cite{}, bioinformatics \cite{}, \ldots

\section{Neural network}
In deep learning, a neural network is known as the most popular method. This is a computing-system based on a collection of connected units (called neurons). Each connection (called synapse) between the neurons can transmit the signal from a neuron to another neuron. The receiving neuron processes the signal that it received, then it sends the resulting signal to another neuron connected to it. Neurons and synaptes may have the weights as learnabled variables, which can used to increase or decrease the strength of signal that it sends to next units. Normally, neurons are organized in layers with different kinds of transformation inside. The signal is travelled multiple times from the first layer (input layer) to the last layer (output layer).

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{images/neuron}
	\caption{A model of neural networks}
	\label{fignnnetworks}
\end{figure}
The image \ref{fignnnetworks} shows a simple model of neural networks. The leftmost layer in this network is called the input layer, the rightmost layer is called the output layer. The neurons within the input layer are called input neurons, the neurons from output layer are called output neurons. When design the network, the input and the output are often straightforward. It means that the neural networks is designed where the output from one layer is used as the input to the next layer, there are no loops in the network, it always feed forward, never feed back, called feedforward networks. The size of a neural network can be to compute as the number of neurons, or the number of parameters.

\section{Deep network}
A deep neural network is a neural network with multiple layers between the input and the output layers. These layers are called hidden layers. Each layer tries to find the correct mathematical operator to turn its input into the next layer. At each layer excepts the output layer, the output is indicated by an activation function i.e sigmoid, tanh, \ldots before transfer to the next layer. Fig. \ref{fignnnetworks} shows an deep network example with one hidden layer. The deep neural network forwards the data from the input layer to the output layer without looping back: The network creates the connections of neurons and assigns the ``weight" for each connection. At each layer, the weights and its input are multiplied and return an output. Further, an algorithm is used to adjust the weights so that make certain parameters more influential until it receives the correct mathematical manipulation on all dataset.

Besides the deep neural network, Convolutional Neural Networks are other solutions for deep learning. It is also similar to neural network. It also consists of an input, an output, as well as multiple hidden layers. The hidden layers of a CNN may be convolutional layers, pooling layers, normalization layers or fully connected layers. An only difference is CNN receives the structured data as the input i.e. images. This change makes the forward functions more efficient and vastly reduce the number of parameters in the network because some of layers in CNN do not contain the learnable parameters i.e. pooling layer or dropout layer. The layers of a CNN has neurons arranged in three dimensions of the input: \textit{width, height and depth} with learnable parameters.

\section{Convolutional neural network}
A Convolutional Neural Network (CNN) is made from a sequential of layers. It takes images as an input, then the images are passed through the series of layers and get the result at the output layer. At each layer, a different function is applied to transform the input data depending on the type of layer. The common layers are used to desgin the CNN includes: convolutional layer, pooling layer, dropout layer, full-connected layer, \ldots. Fig. \ref{} shows an example of a CNN. The image is passed through the functions (i.e. convolution, subsampling) corresponding to the layers of the network before proceduing the output.
