\relax 
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\citation{.}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The dataset images with their manual landmarks.  \textit  {From left to right}: pronotum, head, and body\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figintro}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related works}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Dataset}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An example of augmentation data. From an original image, six augmented version have generated.\relax }}{3}}
\newlabel{figdataaug}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}The model}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {\relax \fontsize  {10.95}{13.6}\selectfont  \abovedisplayskip 11\p@ plus3\p@ minus6\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6.5\p@ plus3.5\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 5\p@ plus2.5\p@ minus\p@ \topsep 10\p@ plus4\p@ minus6\p@ \itemsep 5\p@ plus2.5\p@ minus\p@ {\leftmargin \leftmargini \topsep 9\p@ plus3\p@ minus5\p@ \parsep 4.5\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Network architecture using $3$ \textit  {elementary blocks}. Convolution layer in red, pooling in yellow and dropout in green color.}}\relax }}{4}}
\newlabel{cnnnetwork2}{{3}{4}}
\citation{yosinski2014transferable}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The network parameters in proposed model\relax }}{5}}
\newlabel{model2parameters}{{1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Experiment on the first resolution dataset ($256 \times 192$) }{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experiment on the second resolution dataset ($96 \times 96$) }{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Training on three parts of beetle}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Fine-tuning on pronotum dataset}{5}}
\bibstyle{unsrt}
\bibdata{includes/references}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The losses during training on the images of three parts\relax }}{6}}
\newlabel{figlossallparts}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The blue points present for the predicted landmarks on the images in test set\relax }}{6}}
\newlabel{figtestallparts}{{5}{6}}
\bibcite{yosinski2014transferable}{1}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The losses during fine-tuning model\relax }}{7}}
\newlabel{finetuningloss}{{2}{7}}
\newlabel{model1loss}{{6a}{7}}
\newlabel{sub@model1loss}{{(a)}{a}}
\newlabel{model1test}{{6b}{7}}
\newlabel{sub@model1test}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An result example when fine-tuning the trained model on pronotum dataset\relax }}{7}}
\newlabel{figfintuning}{{6}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training losses and validation loss}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {A pronotum with predicted landmarks}}}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The average error distance per landmark.\relax }}{8}}
\newlabel{tab2}{{3}{8}}
